{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(\n",
    "    model_name='llama-3.1-70b-versatile',\n",
    "    temperature=0.5,\n",
    "    groq_api_key='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Simple QA Chatbot in LangChain**\n",
      "=====================================\n",
      "\n",
      "Below is a simple example of a QA chatbot using LangChain. This chatbot will be able to answer basic questions based on a given text.\n",
      "\n",
      "**Installation**\n",
      "---------------\n",
      "\n",
      "Before running the code, make sure to install the required libraries by running the following command:\n",
      "\n",
      "```bash\n",
      "pip install langchain transformers\n",
      "```\n",
      "\n",
      "**Code**\n",
      "-----\n",
      "\n",
      "```python\n",
      "from langchain import LLMChain, PromptTemplate\n",
      "from langchain.chains.qa import QA\n",
      "from transformers import pipeline\n",
      "\n",
      "# Define the text to answer questions from\n",
      "text = \"\"\"\n",
      "LangChain is a framework for building applications that use large language models.\n",
      "It provides a simple way to create and manage chains of models that can be used for a variety of tasks, such as text generation, question answering, and more.\n",
      "\"\"\"\n",
      "\n",
      "# Define the prompt template for the QA chain\n",
      "template = PromptTemplate(\n",
      "    input_variables=[\"question\"],\n",
      "    template=\"Answer the following question based on the text: {question}\\n\\nText: {text}\",\n",
      ")\n",
      "\n",
      "# Create the LLM chain\n",
      "llm_chain = LLMChain(\n",
      "    llm=pipeline(\"text-generation\", model=\"t5-small\"),\n",
      "    prompt=template,\n",
      ")\n",
      "\n",
      "# Create the QA chain\n",
      "qa_chain = QA(\n",
      "    llm_chain=llm_chain,\n",
      "    input_variables=[\"question\"],\n",
      "    text=text,\n",
      ")\n",
      "\n",
      "# Define a function to interact with the QA chain\n",
      "def ask_question(question):\n",
      "    return qa_chain({\"question\": question})\n",
      "\n",
      "# Example usage\n",
      "print(ask_question(\"What is LangChain?\"))\n",
      "print(ask_question(\"What tasks can LangChain be used for?\"))\n",
      "```\n",
      "\n",
      "**Explanation**\n",
      "--------------\n",
      "\n",
      "1.  We start by installing the required libraries.\n",
      "2.  We define the text to answer questions from.\n",
      "3.  We define a prompt template for the QA chain using `PromptTemplate`. This template takes a `question` as input and provides the text to answer questions from.\n",
      "4.  We create an LLM chain using `LLMChain` and specify the LLM model to use. In this case, we're using the `t5-small` model.\n",
      "5.  We create the QA chain using `QA` and pass in the LLM chain, input variables, and text.\n",
      "6.  We define a function `ask_question` to interact with the QA chain.\n",
      "7.  Finally, we provide example usage of the QA chain by asking two questions.\n",
      "\n",
      "**Note**: This is a basic example and you may want to fine-tune the model and adjust the prompt template to better suit your specific use case.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke('Write a simple qa chatbot in langchain')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
